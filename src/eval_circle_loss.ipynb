{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval Cosine Similairy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考链接：https://github.com/xiangking/PyTorch_CoSENT/blob/main/CoSENT_ATEC.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "a1 = np.random.random((5, 10))\n",
    "b1 = np.random.random((5, 10))\n",
    "\n",
    "a2 = torch.from_numpy(a1)\n",
    "b2 = torch.from_numpy(b1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义正则化的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_normalize(x):\n",
    "    # 这一步相当于求： ||x||\n",
    "    norm = (x ** 2).sum(axis=1, keepdims=True) ** 0.5\n",
    "    # return x / norm\n",
    "    return x / np.clip(norm, 1e-8, np.inf) # np.clip(a, a_min, a_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.72170833, 0.66135354, 0.65483169, 0.7802302 , 0.72604197],\n",
       "       [0.69296034, 0.83372952, 0.63956145, 0.88773847, 0.82563329],\n",
       "       [0.74454191, 0.78951296, 0.7076026 , 0.78417534, 0.78279068],\n",
       "       [0.77675723, 0.72564313, 0.82322539, 0.70335139, 0.81429267],\n",
       "       [0.74744944, 0.81791773, 0.71088846, 0.68847126, 0.80378599]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(a1, b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.72170833, 0.66135354, 0.65483169, 0.7802302 , 0.72604197],\n",
       "       [0.69296034, 0.83372952, 0.63956145, 0.88773847, 0.82563329],\n",
       "       [0.74454191, 0.78951296, 0.7076026 , 0.78417534, 0.78279068],\n",
       "       [0.77675723, 0.72564313, 0.82322539, 0.70335139, 0.81429267],\n",
       "       [0.74744944, 0.81791773, 0.71088846, 0.68847126, 0.80378599]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa1 = l2_normalize(a1)\n",
    "bb1 = l2_normalize(b1)\n",
    "np.inner(aa1, bb1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7217, 0.8337, 0.7076, 0.7034, 0.8038], dtype=torch.float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "F.cosine_similarity(a2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([14.4342, 16.6746, 14.1521, 14.0670, 16.0757], dtype=torch.float64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "λ = 20\n",
    "\n",
    "aa2 = F.normalize(a2, p=2, dim=1, eps=1e-8)\n",
    "bb2 = F.normalize(b2, p=2, dim=1, eps=1e-8)\n",
    "\n",
    "cosine  = torch.sum(aa2 * bb2, dim=1)\n",
    "cosine_scale = λ * cosine\n",
    "print(cosine_scale.shape)\n",
    "cosine_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14.4342],\n",
       "        [16.6746],\n",
       "        [14.1521],\n",
       "        [14.0670],\n",
       "        [16.0757]], dtype=torch.float64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_scale[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14.4342, 16.6746, 14.1521, 14.0670, 16.0757]], dtype=torch.float64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_scale[None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, -2.2404,  0.2821,  0.3671, -1.6416],\n",
       "        [ 2.2404,  0.0000,  2.5225,  2.6076,  0.5989],\n",
       "        [-0.2821, -2.5225,  0.0000,  0.0850, -1.9237],\n",
       "        [-0.3671, -2.6076, -0.0850,  0.0000, -2.0087],\n",
       "        [ 1.6416, -0.5989,  1.9237,  2.0087,  0.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_scale[:, None] - cosine_scale[None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label [1 0 1 0 1]\n",
      "label[:, None] [[1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]]\n",
      "labels[None, :] [[1 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "label = np.array([1, 0, 1, 0, 1], dtype=np.long)\n",
    "print('label', label)\n",
    "print('label[:, None]', label[:, None])\n",
    "print('labels[None, :]', label[None, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000e+00, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12,\n",
       "        -1.0000e+12,  1.4434e+01, -1.0000e+12,  1.4152e+01, -1.0000e+12,\n",
       "         1.6076e+01, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12,\n",
       "        -1.0000e+12,  1.4434e+01, -1.0000e+12,  1.4152e+01, -1.0000e+12,\n",
       "         1.6076e+01, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12,\n",
       "        -1.0000e+12], dtype=torch.float64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.from_numpy(label[:, None] < label[None, :])\n",
    "labels = labels.long()\n",
    "\n",
    "cos_sim = cosine_scale -  (1 - labels) * 1e12\n",
    "\n",
    "# 还要加上一个 1\n",
    "cosine_sim  = torch.cat((torch.zeros(1),cos_sim.view(-1)), dim= 0)\n",
    "cosine_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.9000e+13, dtype=torch.float64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.0613, dtype=torch.float64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.logsumexp(cosine_sim, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 全部流程代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "sent_a = torch.randn(5, 10)\n",
    "sent_b = torch.randn(5, 10)\n",
    "print(sent_a.shape)\n",
    "label_ids = torch.LongTensor([1, 0, 1, 0, 1])\n",
    "λ = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15.9048)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_norm = F.normalize(sent_a, p=2, dim=1, eps=1e-8)\n",
    "b_norm = F.normalize(sent_b, p=2, dim=1, eps=1e-8)\n",
    "# 正则化之后，通过内积求余弦相似度\n",
    "ab_cosine = torch.sum(a_norm * b_norm, dim=1) * λ # (batch_size)\n",
    "# log(1 + ∑e^λ(si - sj))\n",
    "# 实现 ∂(si -sj),其中 λ 取20\n",
    "ab_cosine_diff = ab_cosine[:, None] - ab_cosine[None, :]\n",
    "# 实现的结果 负样本的cosine 值减去 正样本的值，那么 正样本的值应该都是 -np.inf\n",
    "# 通过label_id 进行筛选，并构造和 ab_cosine_diff 一致的数据结构\n",
    "# 如果 是正样本则不应该进行计算，只有negative - positive 对应的位置才是 正值\n",
    "labels = label_ids[:, None] < label_ids[None, :]\n",
    "labels = labels.long()\n",
    "# 将ab_cosine_diff 中不应该计算的值(即labels 中值为0 的位置)映射为 1e-12\n",
    "ab_exp_diff = ab_cosine_diff - (1 - labels) * 1e12\n",
    "# log 里面还有个1， 对应 exp 就是在最前面加一个0\n",
    "ab_exp_diff = torch.cat((torch.zeros(1), ab_exp_diff.view(-1)), dim=0)\n",
    "loss = torch.logsumexp(ab_exp_diff, dim=0)\n",
    "loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dafaadbda7e2b4673c53a13d22366aab1c2a35a28f6b7c4e8046d1a490edd4db"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
